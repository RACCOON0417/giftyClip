{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\nvar API_KEY = 'AIzaSyDsFSET6AdqTZc2Sak-LZF-WpSFB6Ti1wM';\nvar API_URL = \"https://vision.googleapis.com/v1/images:annotate?key=\" + API_KEY;\n\nfunction generateBody(image) {\n  var body = {\n    requests: [{\n      image: {\n        content: image\n      },\n      features: [{\n        type: 'TEXT_DETECTION',\n        maxResults: 1\n      }]\n    }]\n  };\n  return body;\n}\n\nfunction callGoogleVisionAsync(image) {\n  var body, response, result;\n  return _regeneratorRuntime.async(function callGoogleVisionAsync$(_context) {\n    while (1) {\n      switch (_context.prev = _context.next) {\n        case 0:\n          body = generateBody(image);\n          _context.next = 3;\n          return _regeneratorRuntime.awrap(fetch(API_URL, {\n            method: 'POST',\n            headers: {\n              Accept: 'application/json',\n              'Content-Type': 'application/json'\n            },\n            body: JSON.stringify(body)\n          }));\n\n        case 3:\n          response = _context.sent;\n          _context.next = 6;\n          return _regeneratorRuntime.awrap(response.json());\n\n        case 6:\n          result = _context.sent;\n          console.log(result);\n\n        case 8:\n        case \"end\":\n          return _context.stop();\n      }\n    }\n  }, null, null, null, Promise);\n}\n\nexport default callGoogleVisionAsync;","map":{"version":3,"names":["API_KEY","API_URL","generateBody","image","body","requests","content","features","type","maxResults","callGoogleVisionAsync","fetch","method","headers","Accept","JSON","stringify","response","json","result","console","log"],"sources":["C:/Users/ES58/Documents/GitHub/2022HCI-giftyClip/helperFunctions.js"],"sourcesContent":["const API_KEY = 'AIzaSyDsFSET6AdqTZc2Sak-LZF-WpSFB6Ti1wM'; //put your key here.\r\n//this endpoint will tell Google to use the Vision API. We are passing in our key as well.\r\nconst API_URL = `https://vision.googleapis.com/v1/images:annotate?key=${API_KEY}`;\r\nfunction generateBody(image) {\r\n  const body = {\r\n    requests: [\r\n      {\r\n        image: {\r\n          content: image,\r\n        },\r\n        features: [\r\n          {\r\n            type: 'TEXT_DETECTION', //we will use this API for text detection purposes.\r\n            maxResults: 1,\r\n          },\r\n        ],\r\n      },\r\n    ],\r\n  };\r\n  return body;\r\n}\r\n\r\nasync function callGoogleVisionAsync(image) {\r\n    const body = generateBody(image); //pass in our image for the payload\r\n    const response = await fetch(API_URL, {\r\n      method: 'POST',\r\n      headers: {\r\n        Accept: 'application/json',\r\n        'Content-Type': 'application/json',\r\n      },\r\n      body: JSON.stringify(body),\r\n    });\r\n    const result = await response.json();\r\n    console.log(result);\r\n  }\r\n  export default callGoogleVisionAsync;"],"mappings":";AAAA,IAAMA,OAAO,GAAG,yCAAhB;AAEA,IAAMC,OAAO,6DAA2DD,OAAxE;;AACA,SAASE,YAAT,CAAsBC,KAAtB,EAA6B;EAC3B,IAAMC,IAAI,GAAG;IACXC,QAAQ,EAAE,CACR;MACEF,KAAK,EAAE;QACLG,OAAO,EAAEH;MADJ,CADT;MAIEI,QAAQ,EAAE,CACR;QACEC,IAAI,EAAE,gBADR;QAEEC,UAAU,EAAE;MAFd,CADQ;IAJZ,CADQ;EADC,CAAb;EAeA,OAAOL,IAAP;AACD;;AAED,SAAeM,qBAAf,CAAqCP,KAArC;EAAA;EAAA;IAAA;MAAA;QAAA;UACUC,IADV,GACiBF,YAAY,CAACC,KAAD,CAD7B;UAAA;UAAA,iCAE2BQ,KAAK,CAACV,OAAD,EAAU;YACpCW,MAAM,EAAE,MAD4B;YAEpCC,OAAO,EAAE;cACPC,MAAM,EAAE,kBADD;cAEP,gBAAgB;YAFT,CAF2B;YAMpCV,IAAI,EAAEW,IAAI,CAACC,SAAL,CAAeZ,IAAf;UAN8B,CAAV,CAFhC;;QAAA;UAEUa,QAFV;UAAA;UAAA,iCAUyBA,QAAQ,CAACC,IAAT,EAVzB;;QAAA;UAUUC,MAVV;UAWIC,OAAO,CAACC,GAAR,CAAYF,MAAZ;;QAXJ;QAAA;UAAA;MAAA;IAAA;EAAA;AAAA;;AAaE,eAAeT,qBAAf"},"metadata":{},"sourceType":"module"}